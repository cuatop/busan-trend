import requests
import json
import datetime
import re
import os
from collections import Counter
import urllib.parse

# === ì„¤ì • ===
SEARCH_KEYWORDS = [
    "ë¶€ì‚° ë§›ì§‘", "ë¶€ì‚° ì—¬í–‰", "ë¶€ì‚° ê´€ê´‘", "ë¶€ì‚° í•«í”Œ", 
    "ë¶€ì‚° ê°€ë³¼ë§Œí•œê³³", "ë¶€ì‚° ì¶•ì œ", "ë¶€ì‚° í˜„ì§€ì¸ ë§›ì§‘", "ë¶€ì‚° ë°ì´íŠ¸"
]
MAX_RESULTS = 50

API_KEY = os.environ.get('YOUTUBE_API_KEY')

def clean_korean_text(text):
    # 1. ê´‘ê³ /ìŠ¤íŒ¸ í•„í„°ë§ (ì œëª©ì— ì´ëŸ° ë‹¨ì–´ ìˆìœ¼ë©´ ì•„ì˜ˆ ë²„ë¦¼)
    spam_keywords = ["ê´‘ê³ ", "í˜‘ì°¬", "ë¬¸ì˜", "shorts", "Shorts", "ì‡¼ì¸ ", "êµ¬ë…", "ì¢‹ì•„ìš”", "ì§ìº ", "ê³µêµ¬"]
    for spam in spam_keywords:
        if spam in text:
            return []

    # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±°
    text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
    words = text.split()
    
    cleaned_words = []
    # 3. ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ëŒ€ê±° ì‚­ì œ (ìˆœìˆ˜ ëª…ì‚¬/ì§€ëª… ìœ„ì£¼ë¡œ ë‚¨ê¸°ê¸° ìœ„í•¨)
    garbage = set([
        "ë¶€ì‚°", "ë§›ì§‘", "ì—¬í–‰", "ë¸Œì´ë¡œê·¸", "Vlog", "Korea", "Busan", "Food", "Mukbang", "ë¨¹ë°©", 
        "ì¶”ì²œ", "ì½”ìŠ¤", "ì§„ì§œ", "ì •ë§", "í•˜ëŠ”", "ìˆëŠ”", "ê°€ë³¼ë§Œí•œê³³", "Best", "Top", "ì¡´ë§›", 
        "ì˜ìƒ", "ì˜¤ëŠ˜", "íˆ¬ì–´", "í›„ê¸°", "ì‹ë‹¹", "ì¹´í˜", "Cafe", "Street", "Review", "ë¦¬ë·°",
        "2024", "2025", "1ë°•2ì¼", "2ë°•3ì¼", "ì‚¬ëŒ", "ì´ìœ ", "ì¶©ê²©", "ê³µê°œ", "ê°€ì§€", "ëª¨ìŒ",
        "í˜„ì§€ì¸", "ì†”ì§", "ë°©ë¬¸", "ìœ„ì¹˜", "ê°€ê²©", "ë©”ë‰´", "ëŒ€ë°•", "ìœ ëª…í•œ", "ì›¨ì´íŒ…", "í•„ìˆ˜",
        "ì´ì •ë¦¬", "ì‹¤íŒ¨", "ì—†ëŠ”", "ë¬´ì¡°ê±´", "Best5", "Best10", "ë‚´ëˆë‚´ì‚°", "Eng", "Sub",
        "ê´€ê´‘", "í–‰ì‚¬", "í˜ìŠ¤í‹°ë²Œ", "ì¶•ì œ", "Festival", "Trip", "Travel", "í•«í”Œ", "ë°ì´íŠ¸",
        "ê´€ë¦¬", "í†µì œ", "2ë¶€", "1ë¶€", "ê·œëª¨", "ê·œë¬˜", "amp", "ê·¸ë¦¬ê³ ", "ê·¸ë˜ì„œ", "í•˜ì§€ë§Œ", 
        "ê°€ì„¸ìš”", "ì˜¤ì„¸ìš”", "ë¨¹ê³ ", "ë³´ê³ ", "ê°€ì„œ", "ì™€ì„œ", "ë„ˆë¬´", "ë§ì´", "ì§„ì‹¬", "ì—­ëŒ€ê¸‰",
        "í•œêµ­", "ì¼ë³¸", "ì„¸ê³„", "ìµœê³ ", "ë¶„ìœ„ê¸°", "ë¬´ë£Œ", "ì…ì¥", "ì‹œê°„", "ì£¼ì°¨", "ê¿€íŒ"
    ])
    
    # ì¡°ì‚¬/ì–´ë¯¸ ì œê±° ë¦¬ìŠ¤íŠ¸
    suffixes = ["ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì˜", "ì„œ", "ë¡œ", "ê³ ", "í•˜ê³ ", "ì—ì„œ", "ì´ë‘", "ê¹Œì§€", "ë¶€í„°", "ìœ¼ë¡œ", "ë„¤ìš”", "ì„¸ìš”", "ìš°ì™€", "ì¸ê°€", "ì¸ê°€ìš”"]

    for w in words:
        word_to_add = w
        if len(word_to_add) > 2:
            for suffix in suffixes:
                if word_to_add.endswith(suffix):
                    word_to_add = word_to_add[:-len(suffix)]
                    break
        
        # 2ê¸€ì ì´ìƒì´ê³  ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ë‹¨ì–´ë§Œ ì±„íƒ
        if len(word_to_add) >= 2 and word_to_add.lower() not in garbage:
            cleaned_words.append(word_to_add)
            
    return cleaned_words

def get_real_youtube_data():
    all_words = []
    
    if not API_KEY:
        return []

    print("ğŸš€ ê³ ê¸‰ ì •ë³´ í•„í„°ë§ ì¤‘...")
    
    for keyword in SEARCH_KEYWORDS:
        # ì¡°íšŒìˆ˜(viewCount) ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ, ê²€ì¦ëœ ì¸ê¸° ì˜ìƒ ìœ„ì£¼ë¡œ ê°€ì ¸ì˜´
        url = f"https://www.googleapis.com/youtube/v3/search?part=snippet&q={keyword}&key={API_KEY}&maxResults={MAX_RESULTS}&type=video&order=viewCount"
        
        try:
            response = requests.get(url)
            data = response.json()
            
            if 'items' in data:
                for item in data['items']:
                    title = item['snippet']['title']
                    words = clean_korean_text(title)
                    all_words.extend(words)
        except: continue
            
    return Counter(all_words).most_common(80)

try:
    word_counts = get_real_youtube_data()
except:
    word_counts = []

d3_data = []
if word_counts:
    max_count = word_counts[0][1]
    for word, count in word_counts:
        # [í•µì‹¬] í´ë¦­ ì‹œ ê²€ìƒ‰ì–´ ë’¤ì— 'ì†”ì§í›„ê¸° ê¿€íŒ'ì„ ë¶™ì—¬ì„œ ê²€ìƒ‰
        # ì´ë ‡ê²Œ í•˜ë©´ ê´‘ê³ ë‚˜ ì‡¼ì¸ ê°€ ê±¸ëŸ¬ì§€ê³  ì–‘ì§ˆì˜ ì˜ìƒì´ ìƒë‹¨ì— ëœ¸
        search_query = f"ë¶€ì‚° {word} ì†”ì§í›„ê¸° ê¿€íŒ" 
        encoded_query = urllib.parse.quote(search_query)
        link = f"https://www.youtube.com/results?search_query={encoded_query}"
        
        size = 15 + (count / max_count) * 85
        d3_data.append({"text": word, "size": size, "url": link, "count": count})

    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Busan Premium Trends</title>
        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://cdn.jsdelivr.net/gh/holtzy/D3-graph-gallery@master/LIB/d3.layout.cloud.js"></script>
        <link href="https://fonts.googleapis.com/css2?family=Black+Han+Sans&family=Noto+Sans+KR:wght@400;700;900&display=swap" rel="stylesheet">
        <style>
            body { 
                margin: 0; padding: 0; 
                background-color: #e0f7fa; 
                text-align: center; 
                overflow: hidden; 
                font-family: 'Noto Sans KR', sans-serif;
                display: flex; flex-direction: column; align-items: center; justify-content: center;
                height: 100vh;
            }
            #container { width: 100%; height: 100%; display: flex; flex-direction: column; align-items: center; }
            h2 { 
                color: #006064; margin: 20px 0 5px 0; 
                font-family: 'Black Han Sans', sans-serif; 
                font-size: 2.5em; 
                text-shadow: 2px 2px 0px #fff;
            }
            .footer { font-size: 0.9em; color: #555; margin-bottom: 10px; font-weight: bold; }
            .word-link { cursor: pointer; transition: all 0.2s ease; }
            .word-link:hover { opacity: 0.7 !important; text-shadow: 1px 1px 5px rgba(255,255,255,0.8); }
            #cloud-area { width: 100%; flex-grow: 1; display: flex; align-items: center; justify-content: center; }
            svg { width: 100%; height: 100%; display: block; }
        </style>
    </head>
    <body>
        <div id="container">
            <h2>ğŸŒŠ ë¶€ì‚° ì°ë§›ì§‘ & í•«í”Œ íŠ¸ë Œë“œ</h2>
            <p class="footer">Premium Info Analysis â€¢ Updated: __DATE_PLACEHOLDER__</p>
            <div id="cloud-area"></div>
        </div>

        <script>
            var words = __DATA_PLACEHOLDER__;
            var myColor = d3.scaleOrdinal().range(["#01579b", "#0288d1", "#00acc1", "#00bfa5", "#ff6f00", "#d84315", "#c2185b"]);

            // ìº”ë²„ìŠ¤ í¬ê¸° ë„‰ë„‰í•˜ê²Œ (ì˜ë¦¼ ë°©ì§€)
            var layoutWidth = 1200;
            var layoutHeight = 800;

            var layout = d3.layout.cloud()
                .size([layoutWidth, layoutHeight])
                .words(words.map(function(d) { return {text: d.text, size: d.size, url: d.url, count: d.count}; }))
                .padding(6) // ê°„ê²© ì¡°ê¸ˆ ë” ì¤Œ (ê°€ë…ì„±)
                .rotate(function() { return (~~(Math.random() * 6) - 3) * 30; })
                .font("Noto Sans KR")
                .fontWeight("900")
                .fontSize(function(d) { return d.size; })
                .on("end", draw);

            layout.start();

            function draw(words) {
              d3.select("#cloud-area").append("svg")
                  .attr("viewBox", "0 0 " + layoutWidth + " " + layoutHeight)
                  .attr("preserveAspectRatio", "xMidYMid meet")
                .append("g")
                  .attr("transform", "translate(" + layoutWidth / 2 + "," + layoutHeight / 2 + ")")
                .selectAll("text")
                  .data(words)
                .enter().append("text")
                  .attr("class", "word-link")
                  .style("font-size", function(d) { return d.size + "px"; })
                  .style("font-family", "'Noto Sans KR', sans-serif")
                  .style("font-weight", "900")
                  .style("fill", function(d, i) { return myColor(i); })
                  .attr("text-anchor", "middle")
                  .attr("transform", function(d) {
                    return "translate(" + [d.x, d.y] + ")rotate(" + d.rotate + ")";
                  })
                  .text(function(d) { return d.text; })
                  .on("click", function(d) { window.open(d.url, '_blank'); })
                  .append("title")
                  .text(function(d) { return d.text + " (í´ë¦­í•˜ë©´ ì†”ì§í›„ê¸° ì˜ìƒìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤)"; });
            }
        </script>
    </body>
    </html>
    """

    json_str = json.dumps(d3_data)
    today_str = datetime.date.today().strftime('%Y-%m-%d')
    final_html = html_template.replace("__DATA_PLACEHOLDER__", json_str).replace("__DATE_PLACEHOLDER__", today_str)
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(final_html)
else:
    with open("index.html", "w", encoding="utf-8") as f:
        f.write("<h2>No Data Found</h2>")
