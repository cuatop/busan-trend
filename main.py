import requests
import json
import datetime
import re
import os
from collections import Counter
import urllib.parse

# === ÏÑ§Ï†ï ===
SEARCH_KEYWORDS = [
    "Î∂ÄÏÇ∞ ÌòÑÏßÄÏù∏ ÎßõÏßë", "Î∂ÄÏÇ∞ ÎØ∏ÏâêÎ¶∞ Í∞ÄÏù¥Îìú", "Î∂ÄÏÇ∞ Î∏îÎ£®Î¶¨Î≥∏ ÎßõÏßë", 
    "Î∂ÄÏÇ∞ Í∏∞Ïû• Ï∞êÎßõÏßë", "Î∂ÄÏÇ∞ ÏòÅÎèÑ Ìù∞Ïó¨Ïö∏Í∏∏ ÎßõÏßë", "Î∂ÄÏÇ∞ Í¥ëÏïàÎ¶¨ Ïò§ÏÖòÎ∑∞ Ïπ¥Ìéò", 
    "Î∂ÄÏÇ∞ Ìï¥Ïö¥ÎåÄ ÏïîÏÜåÍ∞àÎπÑ", "Î∂ÄÏÇ∞ Ï†ÑÌè¨Îèô Ïπ¥ÌéòÍ±∞Î¶¨", "Î∂ÄÏÇ∞ Íπ°ÌÜµÏãúÏû• Î®πÍ±∞Î¶¨",
    "Î∂ÄÏÇ∞ ÎÖ∏Ìè¨ ÎßõÏßë", "Î∂ÄÏÇ∞ ÎèºÏßÄÍµ≠Î∞• Î°úÏª¨", "Î∂ÄÏÇ∞ Î∞ÄÎ©¥ 3ÎåÄ"
]
MAX_RESULTS = 50

API_KEY = os.environ.get('YOUTUBE_API_KEY')

def clean_korean_text(text):
    # 1. ÏòÅÏñ¥, Ïà´Ïûê, ÌäπÏàòÎ¨∏Ïûê ÏÇ≠Ï†ú
    text = re.sub(r'[a-zA-Z0-9]', ' ', text)
    text = re.sub(r'[^\w\sÍ∞Ä-Ìû£]', ' ', text)
    
    words = text.split()
    cleaned_words = []
    
    # 2. [ÎèÖÌïú ÌïÑÌÑ∞] ÏÑ†ÏÉùÎãòÏù¥ ÏßÄÏ†ÅÌïòÏã† Îã®Ïñ¥ + Ïû°Îã§Ìïú Îã®Ïñ¥ Î∏îÎûôÎ¶¨Ïä§Ìä∏
    garbage = set([
        # ÏßÄÏ†ÅÌïòÏã† Îã®Ïñ¥Îì§
        "ÎåìÍ∏Ä", "ÏÑ†Ï†ï", "ÏÑ†Ï†ïÎêú", "Í∞ÄÎ¥êÏïº", "Í∞ÄÎ≥ºÎßåÌïú", "Ï∂îÏ≤úÌïò", "Ï∂îÏ≤úÌïú", "Ï∂îÏ≤úÌï¥", 
        "Ï∂îÏ≤úÌïòÎäî", "ÌÜ†Î∞ïÏù¥Îì§", "ÌòÑÏßÄÏù∏Îì§", "ÎÇòÌòºÏûê", "ÌòºÏûê", "Í∞ÄÎ¥§ÏäµÎãàÎã§", 
        # ÏßÄÏó≠/Í¥ëÎ≤îÏúÑ Î™ÖÏÇ¨
        "Î∂ÄÏÇ∞", "ÌïúÍµ≠", "Í≤ΩÎÇ®", "Ï†ÑÍµ≠", "ÏßÄÏó≠", "ÎèôÎÑ§", "Íµ≠ÎÇ¥", "Í≤ΩÏÉÅÎèÑ",
        # Ïú†ÌäúÎ∏å ÏÉÅÌà¨Ïñ¥
        "ÎßõÏßë", "Ïó¨Ìñâ", "Í¥ÄÍ¥ë", "Ìà¨Ïñ¥", "ÌõÑÍ∏∞", "Î¶¨Î∑∞", "Î∏åÏù¥Î°úÍ∑∏", "Î®πÎ∞©", "ÏòÅÏÉÅ", 
        "Ï±ÑÎÑê", "Íµ¨ÎèÖ", "Ï¢ãÏïÑÏöî", "ÏïåÎûå", "ÏÑ§Ï†ï", "Í≥µÍ∞ú", "ÌäπÏßë", "Î™®Ïùå", "Î™®ÏùåÏßë",
        "Ï¥ùÏ†ïÎ¶¨", "ÎπÑÍµê", "Î∂ÑÏÑù", "ÏÜåÍ∞ú", "Ï∂îÏ≤ú", "Í∞ïÏ∂î", "Î∞©Î¨∏", "ÌÉêÎ∞©", "ÎèÑÏ†Ñ",
        "Í∞ÄÏù¥Îìú", "Î≤†Ïä§Ìä∏", "best", "top", "Î°úÍ∑∏", "Î∏åÏù¥", 
        # Î¨¥ÏùòÎØ∏Ìïú ÏàòÏãùÏñ¥/ÌòïÏö©ÏÇ¨
        "ÏßÑÏßú", "Ï†ïÎßê", "ÏôÑÏ†Ñ", "ÎåÄÎ∞ï", "Ïó≠ÎåÄÍ∏â", "ÏµúÍ≥†", "Ïú†Î™ÖÌïú", "ÏÜîÏßÅ", "Ïà®ÏùÄ", 
        "ÎÇòÎßå", "ÏïåÍ≥†Ïã∂ÏùÄ", "ÎπÑÎ∞Ä", "Í∞ÄÏÑ±ÎπÑ", "Ï†ÄÎ†¥Ìïú", "ÎπÑÏãº", "Ï°¥Îßõ", "ÍøÄÎßõ", 
        "ÎØ∏Ïπú", "Í∞úÏ©åÎäî", "Î¨¥Ï°∞Í±¥", "Ï†àÎåÄ", "Ïã§Ìå®", "ÏóÜÎäî", "ÏÑ±Í≥µ", "Ïù∏ÏÉù", "Ï∞êÎßõÏßë",
        "Ïú†Î™ÖÌïúÍ≥≥", "Í∞àÎßåÌïúÍ≥≥", "Í∞ÄÎ≥ºÎßåÌïúÍ≥≥", "Ìï´Ìîå", "Ìï´ÌîåÎ†àÏù¥Ïä§",
        # ÏãúÍ∞Ñ/Îã®ÏúÑ/Í∏∞ÌÉÄ
        "Ïò§Îäò", "ÏßÄÍ∏à", "Ïñ¥Ï†ú", "ÎÇ¥Ïùº", "Ï£ºÎßê", "ÌèâÏùº", "ÏãúÍ∞Ñ", "ÏúÑÏπò", "Í∞ÄÍ≤©", 
        "Ï£ºÏ∞®", "ÏòàÏïΩ", "Ïõ®Ïù¥ÌåÖ", "Ïó¨Í∏∞", "Ï†ÄÍ∏∞", "Í±∞Í∏∞", "Ïñ¥Îîî", "Í≥≥ÏùÄ", "Í≥≥Ïù¥", 
        "Í∞ÄÏû•", "Ï†úÏùº", "Î∞îÎ°ú", "Ïó≠Ïãú", "ÌòπÏãú", "Î¨¥Î†§", "ÌäπÌûà", "Ïó∞ÏÜç", "ÎÖÑ", "Ïõî", "Ïùº",
        "ÏÇ¨Îûå", "ÌòÑÏßÄÏù∏", "ÌÜ†Î∞ïÏù¥", "Ïô∏Íµ≠Ïù∏", "Ïª§Ìîå", "Í∞ÄÏ°±", "ÏπúÍµ¨", "ÎÇ®Ïûê", "Ïó¨Ïûê",
        "Îç∞Ïù¥Ìä∏", "ÏΩîÏä§", "Ïó¨ÌñâÏßÄ", "Î™ÖÏÜå", "Ï†ïÎ≥¥", "ÍøÄÌåÅ", "Ïù¥Ïú†", "Ï∂©Í≤©", "Ïã§Ìôî",
        "ÏßàÎ¨∏", "ÎãµÎ≥Ä", "Î∞òÏùë", "Î™®Ïùå", "Í∑ºÌô©", "ÏùºÏÉÅ", "Îî∞Îùº", "Îî∞ÎùºÌïòÍ∏∞"
    ])
    
    # ÎèôÏÇ¨/ÌòïÏö©ÏÇ¨ Ïñ¥ÎØ∏ Ï≤òÎ¶¨ (Í∞ÄÎ¥§ -> Í∞ÄÎã§, Î®πÎäî -> Î®πÎã§ Îì± Î∞©ÏßÄ ÏúÑÌï¥ ÏïÑÏòà ÏÇ≠Ï†ú)
    verb_endings = ["Îã§", "Ïöî", "Ï£†", "ÎÑ§", "Í∞Ä", "ÎÇò", "Îäî", "ÏùÄ", "Î•º", "ÏùÑ", "Ïóê", "ÏÑú", "Î°ú", "ÏôÄ", "Í≥º", "Í≥†", "Î©∞", "Î©¥", "ÏßÄ", "ÎìØ", "Í≤å"]

    for w in words:
        word_to_add = w
        
        # 1Ï∞® ÌïÑÌÑ∞: Ï°∞ÏÇ¨ Ï†úÍ±∞
        if len(word_to_add) > 1:
            for suffix in ["ÏùÄ", "Îäî", "Ïù¥", "Í∞Ä", "ÏùÑ", "Î•º", "Ïóê", "Ïùò", "ÏÑú", "Î°ú", "ÏôÄ", "Í≥º", "ÎèÑ", "Îßå", "ÌïúÌÖå", "ÏóêÏÑú", "Ïù¥Îûë", "ÍπåÏßÄ"]:
                if word_to_add.endswith(suffix):
                    word_to_add = word_to_add[:-len(suffix)]
                    break
        
        # 2Ï∞® ÌïÑÌÑ∞: ÎèôÏÇ¨/ÌòïÏö©ÏÇ¨ ÌôúÏö©Ìòï Í∞ïÎ†• Ï∞®Îã®
        # "Ï∂îÏ≤úÌïò" Í∞ôÏùÄÍ≤å ÎÇ®ÏßÄ ÏïäÎèÑÎ°ù, ÎÅùÏù¥ Ïù¥ÏÉÅÌïòÍ≤å ÎÅùÎÇòÎäî Îßê Ï†úÏô∏
        # (Î™ÖÏÇ¨Îäî Î≥¥ÌÜµ Î∞õÏπ®Ïù¥ ÏûàÍ±∞ÎÇò ÍπîÎÅîÌïòÍ≤å Îñ®Ïñ¥Ïßê)
        is_verb_form = False
        if word_to_add.endswith("Ìïò") or word_to_add.endswith("Ìï¥") or word_to_add.endswith("Ìïú") or word_to_add.endswith("Îêú") or word_to_add.endswith("Îêú") or word_to_add.endswith("Ìï†") or word_to_add.endswith("Îê†"):
             is_verb_form = True

        # [ÏµúÏ¢Ö Ìï©Í≤© Í∏∞Ï§Ä]
        # 1. 2Í∏ÄÏûê Ïù¥ÏÉÅ
        # 2. Î∏îÎûôÎ¶¨Ïä§Ìä∏(garbage)Ïóê ÏóÜÏñ¥Ïïº Ìï®
        # 3. ÎèôÏÇ¨ ÌôúÏö©Ìòï Ï∞åÍ∫ºÍ∏∞Í∞Ä ÏïÑÎãàÏñ¥Ïïº Ìï®
        if len(word_to_add) >= 2 and word_to_add not in garbage and not is_verb_form:
            cleaned_words.append(word_to_add)
            
    return cleaned_words

def get_real_youtube_data():
    all_words = []
    
    if not API_KEY:
        return []

    print("üöÄ ÏµúÍ≥†Í∏â Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú Ï§ë...")
    
    for keyword in SEARCH_KEYWORDS:
        url = f"https://www.googleapis.com/youtube/v3/search?part=snippet&q={keyword}&key={API_KEY}&maxResults={MAX_RESULTS}&type=video&order=viewCount"
        
        try:
            response = requests.get(url)
            data = response.json()
            
            if 'items' in data:
                for item in data['items']:
                    title = item['snippet']['title']
                    words = clean_korean_text(title)
                    all_words.extend(words)
        except: continue
            
    # ÏÉÅÏúÑ 60Í∞úÎßå ÏïÑÏ£º ÏóÑÏÑ† (Í∞úÏàòÎ•º Ï§ÑÏó¨ÏÑú ÌÄÑÎ¶¨Ìã∞ ÎÜíÏûÑ)
    return Counter(all_words).most_common(60)

try:
    word_counts = get_real_youtube_data()
except:
    word_counts = []

d3_data = []
if word_counts:
    max_count = word_counts[0][1]
    for word, count in word_counts:
        search_query = f"Î∂ÄÏÇ∞ {word} Ï∂îÏ≤ú" 
        encoded_query = urllib.parse.quote(search_query)
        link = f"https://www.youtube.com/results?search_query={encoded_query}"
        
        size = 15 + (count / max_count) * 90
        d3_data.append({"text": word, "size": size, "url": link, "count": count})

    html_template = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Busan Premium Trends</title>
        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://cdn.jsdelivr.net/gh/holtzy/D3-graph-gallery@master/LIB/d3.layout.cloud.js"></script>
        <link href="https://fonts.googleapis.com/css2?family=Black+Han+Sans&family=Noto+Sans+KR:wght@400;700;900&display=swap" rel="stylesheet">
        <style>
            body { 
                margin: 0; padding: 0; 
                background-color: #e0f7fa; 
                text-align: center; 
                overflow: auto; 
                font-family: 'Noto Sans KR', sans-serif;
                display: flex; flex-direction: column; align-items: center; justify-content: center;
                min-height: 100vh;
            }
            #container { width: 100%; height: auto; display: flex; flex-direction: column; align-items: center; padding: 20px 0; }
            h2 { 
                color: #006064; margin: 10px 0 5px 0; 
                font-family: 'Black Han Sans', sans-serif; 
                font-size: 3em; 
                text-shadow: 2px 2px 0px #fff;
            }
            .footer { font-size: 0.9em; color: #555; margin-bottom: 20px; font-weight: bold; }
            .word-link { cursor: pointer; transition: all 0.2s ease; }
            .word-link:hover { opacity: 0.7 !important; text-shadow: 1px 1px 5px rgba(255,255,255,0.8); }
            
            #cloud-area { width: 100%; flex-grow: 1; display: flex; align-items: center; justify-content: center; }
            svg { width: 95%; height: auto; max-width: 1200px; display: block; }
        </style>
    </head>
    <body>
        <div id="container">
            <h2>üåä Î∂ÄÏÇ∞ Ï∞êÎßõÏßë & Ìï´Ìîå ÏßÄÎèÑ</h2>
            <p class="footer">Premium Info Analysis ‚Ä¢ Updated: __DATE_PLACEHOLDER__</p>
            <div id="cloud-area"></div>
        </div>

        <script>
            var words = __DATA_PLACEHOLDER__;
            var myColor = d3.scaleOrdinal().range(["#01579b", "#0288d1", "#00acc1", "#00bfa5", "#ff6f00", "#d84315", "#c2185b"]);

            var layoutWidth = 1000;
            var layoutHeight = 800; 

            var layout = d3.layout.cloud()
                .size([layoutWidth, layoutHeight])
                .words(words.map(function(d) { return {text: d.text, size: d.size, url: d.url, count: d.count}; }))
                .padding(5) 
                .rotate(function() { return (~~(Math.random() * 6) - 3) * 30; })
                .font("Noto Sans KR")
                .fontWeight("900")
                .fontSize(function(d) { return d.size; })
                .on("end", draw);

            layout.start();

            function draw(words) {
              d3.select("#cloud-area").append("svg")
                  .attr("viewBox", "0 0 " + layoutWidth + " " + layoutHeight)
                  .attr("preserveAspectRatio", "xMidYMid meet")
                .append("g")
                  .attr("transform", "translate(" + layoutWidth / 2 + "," + layoutHeight / 2 + ")")
                .selectAll("text")
                  .data(words)
                .enter().append("text")
                  .attr("class", "word-link")
                  .style("font-size", function(d) { return d.size + "px"; })
                  .style("font-family", "'Noto Sans KR', sans-serif")
                  .style("font-weight", "900")
                  .style("fill", function(d, i) { return myColor(i); })
                  .attr("text-anchor", "middle")
                  .attr("transform", function(d) {
                    return "translate(" + [d.x, d.y] + ")rotate(" + d.rotate + ")";
                  })
                  .text(function(d) { return d.text; })
                  .on("click", function(d) { window.open(d.url, '_blank'); })
                  .append("title")
                  .text(function(d) { return d.text + " (Click for Info)"; });
            }
        </script>
    </body>
    </html>
    """

    json_str = json.dumps(d3_data)
    today_str = datetime.date.today().strftime('%Y-%m-%d')
    final_html = html_template.replace("__DATA_PLACEHOLDER__", json_str).replace("__DATE_PLACEHOLDER__", today_str)
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(final_html)
else:
    with open("index.html", "w", encoding="utf-8") as f:
        f.write("<h2>No Data Found</h2>")
